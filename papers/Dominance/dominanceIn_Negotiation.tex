\documentclass{llncs}
\usepackage[noend]{algpseudocode}
\usepackage{subcaption}
\usepackage{subfig} 
\usepackage{usual}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{eulervm}
\usepackage{fontenc}
\usepackage{mathrsfs}
\usepackage{multirow}
\usepackage{array}
\usepackage[rflt]{floatflt}
\usepackage{makecell}

\renewcommand\theadalign{cb}
\renewcommand\theadfont{\bfseries}
\renewcommand\theadgape{\Gape[4pt]}
\renewcommand\cellgape{\Gape[4pt]}
\pagestyle{plain}

%
\begin{document}
\title{ Interpersonal dominance in dialogue of cooperative negotiation}
\maketitle 

\par Dominance have been regarded by psychology research as a fundamental dimension of interpersonal relationships \cite{burgoon}. 
%social influence the strategies of dialogue
%collaborative negotiation which is mainly oriented by interlocutors preferences.
% Mental state : pretoferences and vision of the other and relationship
% Agent express their belief and preferences through the utterance they perform

\section{Model of negotiation on preferences}
\subsection{Objects of negotiation}
\par The overall goal of a negotiation in our dialogue model is to choose an \textbf{option} in a set of possible options for a given topic. For instance, on the topic ``Restaurant'', we have a set of options: ``Chuck's cake'', ``The ducking Duck'', ``Ginza sushis''\ldots 
\par Each interlocutor makes its decision by consulting its preferences about these different options. Let $\mathcal{O}$ be the set of options.

To be able to compare these options, interlocutors base their evaluation of each option on a set of \textbf{criteria} that reflect options characteristics.
Let $\mathcal{C}$ be the set of criteria. 
Note that this set is dependent on the topic: the criteria for choosing a restaurant could be cuisine, ambiance, price, and location, while the criteria for choosing a movie could be type and location. 
Furthermore, each criterion has to be measurable, in the sense that it must be possible to rate an option even in qualitative way. Therefore, $\forall$ \emph{c $\in\mathcal{ C}$},  we note \emph{D$_c$} its  domain of values. For example, the domain  values of the criterion cuisine is noted $\emph{D}_{cuisine} = \{chineese, italian\}$.

Each option $O\in \mathcal{O}$ is characterized by a value for each criterion:
 $O = \{c_1=v_1,..., c_n=v_n\}$ with $c_i \in \mathcal{C}, \forall i \in [1,n]$ and $v_i\in \emph{D}_{c_i}$. 
 Thus, we define $\{v(c,O) \in \emph{D}_{c} / \forall O \in \mathcal{O}, \forall c \in \mathcal{C}\}$ as the \emph{objective} value of the criterion $c$ attributed  the option $O$. 
By objective, we mean that this value is independent from the preferences: both interlocutors evaluate the option with the same values, regardless of their preferences. 
For example, Ginza is an expensive Japanese restaurant: $v(price, Ginza) = expensive$ and $(cuisine, Ginza) = japanese$. 

In the following we will present the interlocutor preference model that allows him to represent and decide on preferences.

\subsection{Representation of preferences}

 Preference is a transitive antisymmetric binary relation \emph{P} defined on a set of elements \emph{A}, such that:
 
 \[ \left \{
     \begin{array}{l}
 	\emph{P(a,b)} $ means \emph{a}  is preferred over $\emph{b}. \emph{ a,b} \in \emph{A}\\
 	\emph{P(b,a)} $ means  \emph{b} is preferred over $\emph{a}. \emph{ a,b} \in \emph{A}\\
 $Otherwise, neither is preferred. $\\
     \end{array}
    \right .\]

For example $P_{cuisine} (Japanese, French)$ means that the interlocutor prefers the Japanese cuisine over the French. 

\par  We define the notation \emph{P(a,*)}  = \{$\forall$ \emph{x}$\in$\emph{A}, \emph{P(a,x)}\}, which means that \emph{a} is the \textit{most preferred} element in \emph{A}. 
By opposition, \emph{P(*,b)} = \{$\forall$ \emph{x}$\in$\emph{A}, \emph{P(x,b)}\} means that \emph{b} is the \textit{least preferred} element in \emph{A}.


 
\par Our goal is to be able to define preferences over options of negotiation. 
In the literature \cite{dodgson2009multi}, preference of one option over others depends on the options performances on the set of criteria. This is called multi-criteria decision. In general \cite{dodgson2009multi}, preferences on options are built by inference from preferences over criteria values. This inference can be done using different methods such as ordered weight average (OWA \cite{yager2012ordered}) or Choquet's integrals \cite{chouquet1953}.


\subsection{Decision based on preferences in our model}
\par To produce  dialogues with cooperative negotiation, interlocutors have to take coherent decisions about their preferences over options of a certain topic. Decision on options imply comparing theses options based on interlocutors preferences.  
 Since defining preferences over options is a multi criteria decision that involves calculating how well each option performs on its set of criteria. We have to build a \textbf{preference model }that contains interlocutors preferences on criteria, from which we can infer option preferences.  
In the following, we present the different elements of the preference model noted \textbf{$\mathcal{P}$} : 
\begin{itemize}
	\item \textit{Preferences on option's criteria} noted $\mathcal{P}_O$ is a partially ordered list of interlocutor preferences about the importance of each criterion in the choice of an option. For example, $ P_{Restaurant} = \{(Cuisine, Cost), \ldots\} $
	means that the criterion of cuisine is more important than the Cost to choose a restaurant. 
	\item  \textit{Preferences on the values of criteria}, $\forall c \in \mathcal{C}$, the interlocutor has a list of preferences noted $\mathcal{P}_C = \{(a_1, a_2), ..., (a_i,a_n) | a_i \in D_C \}$ that contains all its pair of preferences on the values of this criterion. 
	\item The preference model \textbf{$\mathcal{P}$} is thus the aggregation of all the preferences defined on the different criteria that define the option $O$. 

\end{itemize}
 \subsubsection{Running example:} 
 To illustrate our approach, we shall use the following running example:
 
 
 User and agent discuss about the topic \textit{Restaurant}. \textit{Restaurant} options are defined with the set of criteria $\mathcal{C} $= \{\textit{Cuisine, Cost, Location, Ambiance}\} and each criterion has its domain of values. We define in this example  a simple representation of the  preference model on the topic \textit{Restaurant} $\mathcal{P}$  that contains the following information: 
 \begin{itemize}
 \item $\mathcal{P}_{Restaurant} = $ \{(Cuisine, Location), (Cost, Ambiance), (Location, Ambiance)\}. $\mathcal{P}_{Restaurant}$ defines the agent preference model  about the criteria that define a restaurant. In this case, the agent believes that the criterion of  \textit{Cuisine} is more important than the criteria  \textit{Location} to choose a restaurant.
 \item In the following, we define  agent preferences on the values of each restaurant criterion: 
 \subitem $\mathcal{P}_{Cuisine} = $\{(French, Japanese), (Italian, Japanese)\}
 \subitem $\mathcal{P}_{Cost} = $ \{(Cheap, Expensive)\}
 \subitem $\mathcal{P}_{Location} = $\{(Paris01, Paris02), (Paris09, Paris01), (Paris01, Paris14)\}
  \subitem $\mathcal{P}_{Ambiance} = $ \{(Calm, Noisy)\}
  \end{itemize}
 
 Thus the preference model of our interlocutor is the aggregation of the all the  preferences that defines the topic Restaurant.  \\$\mathcal{P}_= \{\mathcal{P}_{Restaurant}, \mathcal{P}_{Cuisine}, \mathcal{P}_{Cost}, \mathcal{P}_{Location}, \mathcal{P}_{Ambiance}\} $

 \subsubsection{Selection based on preferences}
\par Once preferences on criteria of the topic are identified and the preference model $\mathcal{P}$ of the interlocutor is built, the interlocutor is provided with enough information to be able to compare two options and calculate the relation 
\\$P(O_1, O_2) / O_1, O_2 \in \mathcal{O} $.
 This comparison is done by calculating each option utility with a multi-criteria decision function. We selected for our model the WA \cite{yager2012ordered} function (weighted averaging) that offers a way of aggregating the preferences calculated on individual criteria to provide an overall utility rate for options. 
  \par We note  $score(a)$ the number of $a$  successors in the preference model $\mathcal{P}$, which means $|\{x \in \mathcal{D} / (a,x) \in \mathcal{P}\}|$. 
  $rank(a)$ is the normalized  score of the criterion $a$, which is calculated by ranking all the values of the specified domain $\mathcal{D}$ by their scores. 
  
Therefore, calculating the utility of an option using the WA is performed as follows: 

 \[U(O) = \sum_{c_j \in \mathcal{C}}  rank_R(c_j) \times score\left( v(O, c_j) \right) \] 
 
 
 \par The relation of preferences between two options is calculated by comparing  options utilities. 
  \[ P(O_1, O_2)  = \left \{
    \begin{array}{l}
	P(O_1, O_2)$ \textit{if}  $U(O_1) > U(O_2) \\
	P(O_2, O_1)$  \textit{if}  $U(O_2) > U(O_1) \\
	$  \textit{Neither is preferred if}  $U(O_2) = U(O_1)\\
    \end{array}
    \right .\]
  
 
\subsubsection{Example of decision}

Suppose that an interlocutor intents to calculate a relation of preference  P(Clementine, Mogoroko), such that 
\{Mogoroko, Clementine\} $\in$ Restaurant. Theses restaurants are described as follow: 
\begin{itemize}
\item Clementine=(Cuisine =\textit{French}, Cost=\textit{Expensive}, Location=\textit{Paris02},
 \\Ambiance=\textit{Calm}).
\item Mogoroko=(Cuisine=\textit{Japanese}, Cost=\textit{Cheap}, Location=\textit{Paris09}, 
\\Ambiance=\textit{Calm}).
\end{itemize}

Thus the utility of each restaurant is calculated as described bellow: 
\begin{itemize}
\item U(Clementine)=$rank$(Cuisine)$\times score$(\textit{French})+$rank$(Cost)$\times score$(\textit{Expensive})\\+$rank$(Location)$\times score$(\textit{Paris02})
+$rank$(Ambiance)$\times score$(\textit{Calm}).
\item U (Mogoroko)= $rank$(Cuisine)$\times score$\textit{Japanese}+$rank$(Cost)$\times score$(\textit{Cheap})\\+$rank$(Location)$\times score$(\textit{Paris09}) +  
$rank$(Ambiance)$\times score$(\textit{Calm})..
\end{itemize}
After calculating both restaurants utilities: U(Clementine)=-3 and U(Mogoroko)=5.
\\  We conclude that $P(Mogoroko, Clementine)$ is true.
 (i.e Mogoroko is more preferred to Clementine).

%Trois étapes :
%- préférences entre les valeurs pour chaque critère (ex) $->$ j'ai des P_c (un pour chaque c)
%- j'ai aussi des préférences entre les critères (ex) $->$ j'ai un P^criteria
%- je calcule les préférences sur les options à partir de ces P_c et de P^criteria (voir fonction section machin)


 \subsection{Mental model of interlocutors}
 
% Dans l'état mental, j'ai deux ensembles de préférences tels que définis ci-dessus ( Pc et P^criteria) : les miennes (je préfère le japonais au chinois) et celles de l'interlocuteur (mon interlocuteur préfère le chinois au japonais) que j'acquiert au fur et à mesure du dialogue.
 
% Notation : Pself et Pother sont des ensembles de prefs
% 
% De plus, je dispose d'un ensemble d'informations partagées: les propositions qui ont été faites (aussi bien en terme de critères (si on allait au chinois) que d'options (si on allait au ducking duck), celles qui ont été rejetées (idem), mais aussi ce que je sais que l'autre a déjà appris de mes préférences (je ne veux pas lui répéter)
 
% Notations: Proposed_option, Proposed_criterai, Rejected_option, Rejected_criteria, Pother-about-self (ToM) : ce que je crois que l'autre sait de moi
% Les quatre premiers sont des listes de critères/options ; le dernier est un ensemble de préférences
% 
% Notations: si Pself est un ensemble de préférences, on note Pself_c et Pself^criteria les sous-ensembles de Pref correspondants...
 
 
 To be able to negotiate in dialogue, the agent  needs a formal representation of its environment namely, its preferences,  user preferences. In addition, the agent has to take into account the current context of the dialogue with all the information shared during the conversation (i.e both interlocutors preferences). 
 
 In the following, we present the formal representation of an interlocutor mental model for dialogue.  
 
 \subsubsection{Preferences model}
 
 \begin{itemize}
 	\item agent preference model is defined with the notation $\mathcal{P}_{self}$.
 	\item User preference model as perceived by the agent during the dialogue is  defined with the notation $\mathcal{P}_{other}$.
 	\item In addition, the agent has to model  the user  knowledge about him based on the interaction (i.e Theory of mind; what the user knows about me). We note it   $\mathcal{P}_{other-about-self}$.
 \end{itemize}

 
\subsubsection{Dialogue context}
 
During dialogue, interlocutors  negotiate  about a topic and its criteria. The final decision is to select an option (\emph{e.g.} let's go to Ginza restaurant). Therefore, interlocutors share information about their preferences and propose decisions to their negotiation (\emph{e.g.} let's go to a Japanese restaurant, we can't afford expensive restaurant, or let's go to Ginza). To represent these elements of negotiation, we use the following notations to define the status of proposals.

We first define a proposal as a tuple $Proposal(Type, Value)$ where  $Type$ is either the the topic (for example Restaurants) or a criterion $c \in \mathcal{C}$ and value is:
\begin{itemize}
	\item an option $O \in \in \mathcal{O}$ if $Type \in Topic$ 
	\item a value $v \in \emph{D}_c$ if $Type \in \mathcal{C}$
\end{itemize}
    

In order to keep track of all the proposals made during the dialogue, we define the following structures that defines the different status of a proposal can take during a negotiation:
 \begin{itemize}
	 	\item $Proposed$ is the set of all the open proposals made during the dialogue.
	 	\item $Rejected$  is the set of rejected proposals.
	 	\item $Accepted$  is the set of accepted proposals.
 \end{itemize}


\subsubsection{Utterances semantic}
Agents communicate using utterances that encapsulate the message. In dialogue, messages are represented as actions, they are defined with precondition, postconditions and effects that update both interlocutors mental states. The preconditions are all optional, because the message selection depends first on the interlocutor dialogue strategy. For utterance effects, we only represent the  agent's perception of its environment (i.e. his preferences and user preferences). We cannot represent the user belief, we only represent the agent perception of the user belief. For example, suppose that the agent states that he prefers Japanese cuisine over Chinese. By consequence, the agent adds this preference to its $\mathcal{P}_{o-a-s}$ model, but we don't have no certainty that the user adds this preference to its $\mathcal{P}_{other}$  model.

 Note that the effect of an utterance updates only the belief of the agent about a preference, but in any case it can update the values of the preference model.

\begin{table}

\caption{\label{tab: utt} dialogue utterances semantic}
\begin{tabular}  {|m{0.40cm}|m{4cm}|m{2cm}|m{2.5cm}|m{3cm}|m{3cm}|}

\hline 
N & \thead{Utterance} & \multicolumn{2}{c|} {\thead{Preconditions}  } &  \multicolumn{2}{c|} {\thead{Effects}  } \\
\hline 
1 & \makecell{State.Preference(\textit{$a,b$}):\\ ``I prefer $a$ over $b$''}& \multicolumn{2}{c|} {\makecell{ $(a,b)\in$ $\mathcal{P}_{self}$  \\ $(a,b) \notin$ $\mathcal{P}_{o-a-s}$} }&\makecell{ \textit{(hearer case)} \\ $add((a,b)$, $\mathcal{P}_{other})$ } & \makecell{\textit{(speaker case)} \\ $add((a,b)$, $\mathcal{P}_{o-a-s})$}  \\
\hline
2 & \makecell{Ask.Preference(\textit{$a,b$}):\\``Do you prefer $a$ to $b$'' ?}& \multicolumn{2}{c|} {\makecell{ $ (a,b) \notin \mathcal{P}_{other} $} }&
\multicolumn{2}{c|} {\makecell{None} } \\
\hline
3 & \makecell{Propose(\textit{Proposal(T,V)}):\\``Let's choose  \textit{V}''}& \multicolumn{2}{c|} {\makecell{$ Proposal(T,V) \notin  Proposed$} }&\multicolumn{2}{c|} {\makecell{ $add(Proposal(T,V), Proposed)$ }} \\
\hline
4 & \makecell{Accept(\textit{Proposal(T,V)}):\\``Okay, let's choose \\ \textit{V} for \textit{T}''}& \multicolumn{2}{c|} {\makecell{$Proposal(T,V) \in Proposed$ \\ $ Proposal(T,V)\notin Accepted$} } & \multicolumn{2}{c|} { \makecell{$add(Proposal(T,V), Accepted)$\\$ remove(Value, Proposed)$}  }  \\
\hline
5 & \makecell{Reject(\textit{Proposal(T,V)}):\\`` Sorry, I would choice \\ something else.''}& \multicolumn{2}{c|} { \makecell{$Proposal(T,V) \in Proposed$ \\$Proposal(T,V)\notin Rejected$}  } & \multicolumn{2}{c|} {\makecell{ $add(Proposal(T,V),Rejected)$ \\$remove(Proposal(T,V), Proposed)$}} \\
\hline
\end{tabular}
\end{table}
\par  Our aim was to define utterances with semantic that allows interlocutors to handle cooperative negotiation in dialogue. The proposed utterances are summarized in the table \ref{tab: utt}. We define in details the semantic of each utterance.
\begin{enumerate}
	\item  State.Preference utterance allows the agent to express his preference. For example: State.Preference$_{cuisine}(\textit{Japanese , Chinese})$ : ``I prefer japanese cuisine over Chinese''. 
	\\The  sender of the utterance (speaker) has to belief the preference statement (i.e it has to be defined in his preference model). Note that effect of the state utterance is different whether the agent is the speaker or the hearer. Thus,  the speaker updates its mental state about the hearer's knowledge about him. In addition, $(a,b) \in \mathcal{P}_{other-about-self}$ does not prevent from sending redundant information (I can try to insist on an already stated preferences): this depends on the dialogue strategy (see section X below). In parallel, The hearer updates its mental state about the speaker preferences.	
	\par We define two variant valuations on stating preferences: 
	 	\subitem State.Preference(\textit{$a, *$}): ``I prefer the most $a$''.
	 	\subitem State.Preference(\textit{$*, a$}): ``I don't like /hate $a$''.
	 	\subitem In this model, we cannot express indifference about preferences.%
	 	\\
	\item Ask.utterance is defined to enrich speaker knowledge about the hearer preferences. For  example: Ask.Preference$_{cuisine}$(\textit{$Japanese , Chinese$}) : Do you prefer japanese cuisine or chinese?, is sent because the speaker has no belief about the hear preference on those elements. 
	\par We define two variant valuations as follows: 
	 	\subitem Ask.Preference(\textit{$Pref_{j}(a, *)$}): ``Do you like $a$?''
	 	\subitem Ask.Preference(\textit{$*$}): ``What do you like ?.'' This case appear when the speaker has any belief on the hear preferences on the current topic$\mathcal{P}= \emptyset$. 
	\\
	\item Propose (Proposal(T,V)) allows the speaker to make a proposal. The effect of this utterance is to update interlocutors shared information about the negotiation.
	\\ For example: Propose.Preference(\textit{$cuisine,Japanese$}) : ``Let's choose japanese cuisine'', will update both interlocutor information about the dialogue context, in the way that \textit{Japanese} is added to \textit{Proposed}.
	\\
	\item Accept (Proposal(T,V)), indicates to the hearer that the speaker accepts the proposal \textit{V} for \textit{T} which has been the subject of a previous  proposal. We belief that there is no update of the belief on preference model because the speaker accepts a proposal if it is consistent with its strategy of dialogue and not necessarily with its preferences. For example : 
	
		\subitem Other: Propose.Criterion (Proposal(Cuisine, Indian)):`` Let's choose Indian cuisine.''
		\subitem Self: Accept.Criterion (Proposal(Cuisine, Indian)): ``Okay, lets choose Indian cuisine.''
		\\The agent accepts this proposal while Indian$\notin \mathcal{P}_{self_{Cuisine}}$ because in its strategy of dialogue, he prioritizes the other preferences (submissive interlocutor).
	\\	
	\item Reject (Proposal(T,V)): this utterance has the same semantic of an Accept utterance, it occurs after a proposal and the proposed value doesn't respect the speaker goals. For example: 
		\subitem Other: Propose.Criterion (Proposal(Cuisine, Indian)): ``Let's choose Indian cuisine.'' 
		\subitem Self: Accept.Criterion (Proposal(Cuisine, Indian)):`` Sorry, I would choose something else.'' 
	\\
	
\end{enumerate}
 
 \section{Dominance in dialogue}
\par Despite the various definitions of dominance available in the fields of interpersonal communication and psychology, scholars are converging to a general definition of dominance as the power to produce intended effects, and the ability to influence the behavior of other person in the conversation. (Bachrach \& Lawler, 1981; Berger, 1994; Burgoon et al.,
1998; Foa\& Foa, 1974; French \& Raven, 1959; Gray-Little \& Burks, 1983;
Henley, 1995; Olson \& Cromwell, 1975; Rollins \& Bahr, 1976). Dominance is generally viewed as a personality trait, or to describe the social role of an individual inside a group. However, in the context of communication, dominance is a dyadic variable where one individual's attempt of control is necessarily acquainted by the partner in the interaction.(Rogers-Millar and Millar, 1979,Dunba and Burgoon, 2005). 
\par Dominant behaviors in a conversation can contribute either positively or negatively to the discussion. For example, positive contributions include actions such as keeping the conversation going, orient the task decision, by making quick decisions and conclusions etc. Negative contribution may include not considering the partner in the conversation, for example, not giving the occasion to express his opinion, not open to criticism. In addition, expressing verbally the dominance can be viewed as offensive and unjustified (K,Zablotskaya). Giving these contributions to the conversation, several researches get interested to detect  behaviors related to the dominance during the conversation. We focus essentially on the context of conversation of negotiation, where several researches already proved the impact of dominance on the negotiation(VAN KLEEF, 2005)

 \subsection{Behaviors of dominance in dialogue}
 
 \subsubsection{Verbal behavior}
  \subsubsection{Non-verbal behavior}
\noindent 
\vskip 4pt
\bibliographystyle{plain}
\bibliography{abbrevs,Library}
\end{document}
