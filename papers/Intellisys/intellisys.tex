	
	%% bare_conf.tex
	%% V1.3
	%% 2007/01/11
	%% by Michael Shell
	%% See:
	%% http://www.michaelshell.org/
	%% for current contact information.
	%%
	%% This is a skeleton file demonstrating the use of IEEEtran.cls
	%% (requires IEEEtran.cls version 1.7 or later) with an IEEE conference paper.
	%%
	%% Support sites:
	%% http://www.michaelshell.org/tex/ieeetran/
	%% http://www.ctan.org/tex-archive/macros/latex/contrib/IEEEtran/
	%% and
	%% http://www.ieee.org/
	
	%%*************************************************************************
	%% Legal Notice:
	%% This code is offered as-is without any warranty either expressed or
	%% implied; without even the implied warranty of MERCHANTABILITY or
	%% FITNESS FOR A PARTICULAR PURPOSE! 
	%% User assumes all risk.
	%% In no event shall IEEE or any contributor to this code be liable for
	%% any damages or losses, including, but not limited to, incidental,
	%% consequential, or any other damages, resulting from the use or misuse
	%% of any information contained here.
	%%
	%% All comments are the opinions of their respective authors and are not
	%% necessarily endorsed by the IEEE.
	%%
	%% This work is distributed under the LaTeX Project Public License (LPPL)
	%% ( http://www.latex-project.org/ ) version 1.3, and may be freely used,
	%% distributed and modified. A copy of the LPPL, version 1.3, is included
	%% in the base LaTeX documentation of all distributions of LaTeX released
	%% 2003/12/01 or later.
	%% Retain all contribution notices and credits.
	%% ** Modified files should be clearly indicated as such, including  **
	%% ** renaming them and changing author support contact information. **
	%%
	%% File list of work: IEEEtran.cls, IEEEtran_HOWTO.pdf, bare_adv.tex,
	%%                    bare_conf.tex, bare_jrnl.tex, bare_jrnl_compsoc.tex
	%%*************************************************************************
	
	% *** Authors should verify (and, if needed, correct) their LaTeX system  ***
	% *** with the testflow diagnostic prior to trusting their LaTeX platform ***
	% *** with production work. IEEE's font choices can trigger bugs that do  ***
	% *** not appear when using other class files.                            ***
	% The testflow support page is at:
	% http://www.michaelshell.org/tex/testflow/
	
	
	
	% Note that the a4paper option is mainly intended so that authors in
	% countries using A4 can easily print to A4 and see how their papers will
	% look in print - the typesetting of the document will not typically be
	% affected with changes in paper size (but the bottom and side margins will).
	% Use the testflow package mentioned above to verify correct handling of
	% both paper sizes by the user's LaTeX system.
	%
	% Also note that the "draftcls" or "draftclsnofoot", not "draft", option
	% should be used if it is desired that the figures are to be displayed in
	% draft mode.
	%
	\documentclass[conference, letterpaper]{IEEEtran}
	\usepackage{booktabs}
	\usepackage[rflt]{floatflt}
	\usepackage{frame, caption}
	\usepackage{mathrsfs}
	\usepackage{array}
	\usepackage{amsmath,amssymb}
	\usepackage{color}
	%
	\usepackage{fancyhdr}
	\usepackage[caption=false,font=footnotesize]{subfig}
	\newcommand{\argmax}{\operatornamewithlimits{arg\,max}}
	% correct bad hyphenation here
	\hyphenation{op-tical net-works semi-conduc-tor}
	
	%\usepackage{subcaption}
	
	% *** GRAPHICS RELATED PACKAGES ***
	%
	\ifCLASSINFOpdf
	   \usepackage[pdftex]{graphicx}
	\else
	\fi
	
	
	%
	
	\renewcommand{\thispagestyle}[2]{} 
	
	
	\fancypagestyle{plain}{
	        \fancyhead{}
	        \fancyhead[C]{first page center header}
	        \fancyfoot{}
	        \fancyfoot[C]{first page center footer}
	}
	\pagestyle{fancy}
	
	
	\headheight 20pt
	\footskip 20pt
	
	\rhead{}
	
	%Enter the first page number of your paper below
	\setcounter{page}{1}
	
	%Header
	\fancyhead[R]{\textit{Intelligent Systems Conference 2018 \\ 6-7 September 2018 $|$ London, UK}}
	\renewcommand{\headrulewidth}{0pt}
	
	%Footer
	\fancyfoot[C]{IEEE}
	\renewcommand{\footrulewidth}{0.5pt}
	\fancyfoot[R]{\thepage \  $|$ P a g e }
	
	
	\begin{document}
	
	%
	% paper title
	% can use linebreaks \\ within to get better formatting as desired
	\title{I've got the power's value! A computational model to evaluate the interlocutor's behaviors in collaborative negotiation}
	
	
	% author names and affiliations
	% use a multiple column layout for up to three different
	% affiliations
%	\author{\IEEEauthorblockN{Michael Shell}
%	\IEEEauthorblockA{School of Electrical and\\Computer Engineering\\
%	Georgia Institute of Technology\\
%	Atlanta, Georgia 30332--0250\\
%	Email: http://www.michaelshell.org/contact.html}
%	\and
%	\IEEEauthorblockN{Homer Simpson}
%	\IEEEauthorblockA{Twentieth Century Fox\\
%	Springfield, USA\\
%	Email: homer@thesimpsons.com}
%	\and
%	\IEEEauthorblockN{James Kirk\\ and Montgomery Scott}
%	\IEEEauthorblockA{Starfleet Academy\\
%	San Francisco, California 96678-2391\\
%	Telephone: (800) 555--1212\\
%	Fax: (888) 555--1212}}
	
	% conference papers do not typically use \thanks and this command
	% is locked out in conference mode. If really needed, such as for
	% the acknowledgment of grants, issue a \IEEEoverridecommandlockouts
	% after \documentclass
	
	% for over three affiliations, or if they all won't fit within the width
	% of the page, use this alternative format:
	% 
	%\author{\IEEEauthorblockN{Michael Shell\IEEEauthorrefmark{1},
	%Homer Simpson\IEEEauthorrefmark{2},
	%James Kirk\IEEEauthorrefmark{3}, 
	%Montgomery Scott\IEEEauthorrefmark{3} and
	%Eldon Tyrell\IEEEauthorrefmark{4}}
	%\IEEEauthorblockA{\IEEEauthorrefmark{1}School of Electrical and Computer Engineering\\
	%Georgia Institute of Technology,
	%Atlanta, Georgia 30332--0250\\ Email: see http://www.michaelshell.org/contact.html}
	%\IEEEauthorblockA{\IEEEauthorrefmark{2}Twentieth Century Fox, Springfield, USA\\
	%Email: homer@thesimpsons.com}
	%\IEEEauthorblockA{\IEEEauthorrefmark{3}Starfleet Academy, San Francisco, California 96678-2391\\
	%Telephone: (800) 555--1212, Fax: (888) 555--1212}
	%\IEEEauthorblockA{\IEEEauthorrefmark{4}Tyrell Inc., 123 Replicant Street, Los Angeles, California 90210--4321}}
	
	
	
	
	% use for special paper notices
	%\IEEEspecialpapernotice{(Invited Paper)}
	
	
	
	
	% make the title area
	\maketitle
	
	
	\begin{abstract}
		%\boldmath
		Interpersonal dominance relation has a major effect on the outcome of a negotiation. It has been shown that when participants adopt complementary dominance behaviors (one being dominant and the other being submissive), they reach mutually beneficial outcomes and this increases their reciprocal likings. In this paper, we investigate about the simulation of this interpersonal relationship in the context of collaborative negotiation between artificial agents.
		
		Our simulation is based on a previously published model. We present a Theory of Mind model that allows an agent to evaluate its interlocutor's level of dominance. The agent establishes the relation of dominance by adapting its behavior of power to complement the power of its interlocutor. We show on agent-agent simulation that the system correctly predicts the interlocutor's power. 
	\end{abstract}
	% IEEEtran.cls defaults to using nonbold math in the Abstract.
	% This preserves the distinction between vectors and scalars. However,
	% if the conference you are submitting to favors bold math in the abstract,
	% then you can use LaTeX's standard command \boldmath at the very start
	% of the abstract to achieve this. Many IEEE journals/conferences frown on
	% math in the abstract anyway.
	
	% no keywords
	
	
	\begin{IEEEkeywords}
		
		Human agent interaction ; Collaborative negotiation; Interpersonal relation of power;Reasoning about other; Theory of mind
	\end{IEEEkeywords}
	
	
	% For peer review papers, you can put extra information on the cover
	% page as needed:
	% \ifCLASSOPTIONpeerreview
	% \begin{center} \bfseries EDICS Category: 3-BBND \end{center}
	% \fi
	%
	% For peerreview papers, this IEEEtran command inserts a page break and
	% creates the second title. It will be ignored for other modes.
	\IEEEpeerreviewmaketitle
	
		Recent years have witnessed substantial growth in research on interactions between humans and intelligent agents and robots. Many new applications require agents to collaborate with the human in order to achieve joint goals and tasks. These includes agents such as an \textit{eCoach} collaborating with a patient to choose a course of treatment from among many viable options \cite{robertson2015visual}, or an educational agent collaborating with a student to resolve problems \cite{howard2017shifting} along side with companion for eldery. In such situations, users might have to negotiate with the conversational agent regarding the plan that achieves their common goals in a way that both satisfies them. This type of negotiation is called \emph{"Collaborative negotiation"}. It assumes that each participant is driven by the goal of finding a trade-off that best satisfies the interests of all the participants as a group, instead of one that maximizes his own interest \cite{sidner1994artificial,chu1995response}.
	
	%	Negotiation is a common task in daily life. People negotiate not only in professional situations (\emph{e.g.} for a salary increase or a promotion) but also in more simple situations such as choosing the movie to watch or the holiday destination. In the last decade, a variety of conversational agents have been created to negotiate with people \cite{pynadath2013you,gratch2016misrepresentation,klatt2011negotiations}. Theses agents are designed with a growing number of decisional abilities, including multi-party and multi-issues negotiation capabilities.
	
		However, negotiation is a multifaceted process which also involves social interaction and affects as well as personal preferences and opinions  \cite{bro2010affective}. Several research considered the role of social behavior in the negotiation process. For instance, \cite{de2011effect} studied the impact of emotions of anger and happiness on the outcome of the negotiation.  \cite{kraus1995designing} developed an agent that behaves according to different personalities	and has a learning mechanism to learn the personality of its opponents. 
	
		One key element in the social aspect of negotiation is the interpersonal relation between the participants. Indeed, researches in social psychology demonstrated that the relation of dominance affects the way the negotiation process is perceived by the participants \cite{van2006power}.  
		Negotiating parties often differ in terms of dominance and this difference exerts an important influence on the behavior of participants. Negotiators build different negotiation's strategies depending on their relative dominance. This directly influences the outcomes of the negotiation. More precisely, Tidens \cite{tiedens2003power} showed that dominance complementarity (\emph{i.e.} one negotiator exhibits dominant behaviors while the other one responds with submissive ones) leads the negotiators to reach mutually beneficial outcomes and increases their reciprocal likings. \cite{wiltermuth2015benefits,tiedens2003power}.
	
		When building conversational agents that collaborate with a human user. It is important  to take into account the interpersonal relationship that they establish. We focus in this paper on the relation of dominance for the reasons cited above. \cite{burgoon1998nature} defined interpersonal dominance as expressive, relationally based communicative acts by which behaviors of power are exerted and influence achieved. they further defined dominance as a dyadic variable in which control attempts by one individual are accepted by the partner, which means if one individual expresses behaviors of high power, the interactional partner will adapt with a low power behavior. 
	
		To express those behaviors of power, we designed a model of collaborative negotiation that allows an agent to express its power through negotiation strategies \cite{ouali2017computational}. We showed that human observers correctly perceived the power expressed by the agent.
		The next step is to extend this model in order to simulate an interpersonal relation of dominance between the agent and the user. This means that if one negotiator exerts behaviors of high power, its partner has to adapt in order to exert complementary behaviors of low power, and vice versa.
		
		 For this aim, the agent has adapt its social behavior to the power expressed by his interlocutor. Our work aims at developing such a system that is capable of evaluating and adapting to this degree of power expressed by the interactional partner. We propose a model of theory of mind based on \emph{simulation-theory (ST)} \cite{gordon1986folk} to evaluate the behaviors of the partner. \emph{ST} suggests that, we humans, have the ability to project oneself in the other person’s shoes \cite{shanton2010simulation}. Therefore, we can simulate his or her mental activity with our own capacities for practical reasoning. It allows us to mimic the mental state of our interactional partner \cite{harbers2009modeling}.%\cite{http://ii.tudelft.nl/~maaike/papers/Iat_2009.pdf}
		  
		 This paper describes our model of \emph{ST} that allows the agent to simulate the behaviors of its partner and reason about it to predict its intentional power as presented in the figure~\ref{fig:schema-general}. The agent assumes that its partner has a similar decision's model based on power. Therefore, for each enunciated utterance by the user, the agent tries to guess the behavior of power that its partner intends to express. In addition, we present the first step of our validation process, that aims to validate the accuracy of prediction made on the partner's behaviors. We study in the context of agent/agent interaction, in which one agent is implemented with our model of \emph{ST}, the degree of exactitude the agent guessed its interlocutor's behaviors of power. 
		 
		 % We present an experiment in which we aim to study the accuracy ot the agent's guessing of it interlocutor behaviors of power.
	
	
		\begin{figure*}
			\centering
			\includegraphics[width=0.75\linewidth, height= 0.2\textheight]{figs/model.png}
			\caption{Model of collaborative negotiation with a model of other} 
			\label{fig:schema-general}
		\end{figure*} 
	

		The paper is organized as follows. Section II gives an overview of previous automated negotiation agents with theory of mind and other related work on social behavior recognition. In section III, we briefly present our model of dialogue for collaborative negotiation. We show that extending this model with a theory of mind raises computational issues. We propose a new model to evaluate the dominance of the interlocutor. This model is based on reasoning with uncertainty. Section IV presents an evaluation of this new model in the context of agent-agent negotiation. We show that the system correctly predicts the interlocutor's power in spite of the restrictions on the model. In section V, we discuss the future use of this new model for building an adaptive negotiator agent.
	
	
	\section{Related works}
	
	%https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3737477/ pour plus d'exemple de tom 
	In social interactions and negotiation in particular, reasoning about the beliefs, goals, and intentions of others is crucial. People use this so-called theory of mind \cite{premack1978does} or mentalizing to understand why others behave the way they do, as well as to predict the future behavior of others. Therefore, various negotiation models use theory of mind approaches to create  more realistic models of negotiation. 
	
	For instance, Pynadath \textit{et al}\cite{pynadath2013you} showed the advantages of theory of mind on negotiation even with an overly simplified model. They observed significant similarities between	the partner behaviors and the agent's idealized expectations. Moreover, deviations in expectations about the other did not affect the agent performances and played in some cases in the advantage of the agent.
	
	De Weerd \textit{et al} \cite{de2013higher} also investigated the use of high-order theory of mind in mixed-motive situations where cooperative and competitive behaviors play an important role. They found that the use of first-order and second-order theory of mind allow agents to balance competitive and cooperative	aspects of the game. This prevents agents from breaking down compared to  agents without theory of mind.
	
	
	Both approaches only focus on rational behaviors and exclude social aspects. However, the impact of social behaviors has been extensively debated in social psychology. Among such works, various researches have been investigating emotion recognition in negotiation; the effects of one individual's	emotions on the other's social decisions and behavior during the negotiation. Moreover, they investigate how theses resource of information are integrated.
	For example, Elfenbein\textit{ et al} \cite{elfenbein2007reading} proved that  emotion recognition accuracy is positively correlated to  better performances in negotiation
	
	In the same vein, several researches suggested that anger expression has effects on the negotiation \cite{sinaceur2006get,van2010interpersonal,ferguson2004social}. For example, VanKleef \cite{van2004interpersonal} demonstrated that negotiators monitor their opponent's emotions and use them to estimate the opponent's limits, and modify their demands according to the presumed location of those limits. As a result, negotiators concede more to an angry opponent than to a happy one. 
	
	
	For theses reasons, reasoning about the social behaviors is important for the perspective of constructing negotiators agents. \cite{alfonso2015emotional} proposed a model that can observe and predict other's agents emotional behaviors. The three step method proposes to revise the agent's  beliefs by integrating a Bayesian model which infers probabilities about the emotional behaviors of other's agents and compute probabilistic prediction about their appraisals.
	
	Marcella \textit{et al} \cite{klatt2011negotiations} proposed a model of negotiation in the context of aid prevention. The model tries to combine handling of emotions with general structures of negotiations. 
	
	In the context our work, we focus on the impact of dominance in the negotiation. Dominance as an interpersonal relation is defined by burgoon \cite{burgoon1998nature} as expressive, relationally based communicative acts by which power is exerted and influence achieved. Furthermore, it is a dyadic variable in which control attempts by one individual are accepted by the
	interactional partner \cite{dunbar2005perceptions}. For this reason, we focus on dominance complementarity between a negotiator agent and a human user in the context of collaborative negotiation. 
	
	Dominance complementarity is characterized by one person in a dyadic interaction behaving dominantly and his counterpart behaving submissively \cite{tiedens2003power} and those behaviors have been investigated in the context of negotiation. \cite{tiedens2003power} showed that when complementarity occurs in an interaction, people feel more comfortable and helps to create interpersonal liking relation.
	Moreover, \cite{wiltermuth2015benefits} showed that dominance complementarity can positively improve coordination and by consequences improve objective benefits.
	
	Our goal is to create a model of negotiation in which the agent adapts its negotiation strategies to the relation of dominance established with the user. Therefore, the agent has to reason about user's behaviors of \emph{power} to understand the level of dominance or submissiveness expressed. The agent then adopt a complementary strategy in order to complement the user behaviors and establish the relation of dominance.
	
	We present in this paper a model of theory of mind that builds beliefs about the user behaviors of power in order to predict his behavior of dominance. We propose to use our model of negotiation based on power in order to reason about the user behaviors. 
	
	
	\section{Model of collaborative negotiation}
	The goal of our presented work is to simulate an interpersonal relation of dominance. We allow the agent to adapt its behaviors of power to complement its partner behavior. We use a model inspired form simulation theory to guess the power of the partner. To this aim, we will use and adapt our model of collaborative negotiation to guess the partner's behavior. In this model of collaborative negotiation, the decisional process is governed by the power the agent seek to express. Indeed, the strategies expressed by the agent are influenced by power. Theses strategies were designed based on researches from social psychology which studied the impact of power on negotiator's strategies. 
	%Indeed, in addition the agent's preferences,the decisional process of this model takes into account the power of this agent to make decisions during the negotiation.
	
	In this section, we present an overview of our collaborative negotiation model. Indeed, It is not necessary to have a complete knowledge of this dialogue model to understand the simulation presented here. However, some elements are required to explain our approach. This section briefly presents the main principles of the collaborative negotiation dialogue model. The detailed presentation is explained in a previous work  \cite{ouali2017computational}.
	

	
	
%	------------------------------------------
%	Our simulation of interpersonal relation of dominance is based on a previously proposed model of collaborative negotiation.  In this model, the artificial agent selects an utterance based on the previously exchanged information and on its personal level of social power, represented as a variable in [0,1]. We showed that the dialogues produced by this model allow human users to correctly perceive the different dimensions of social power expressed by the agent.
%	
%	Our goal is to use this dialogue model to simulate the interlocutor's behavior. From a given utterance produced by the interlocutor, the agent will try to evaluate the level of power by comparing this utterance with the possible outcomes of the dialogue model.
%	
%	It is not necessary to have a complete knowledge of this dialogue model to understand the simulation presented here. However, some elements are required to explain our approach. This section briefly presents the main principles of the collaborative negotiation dialogue model.
	
	\subsection{Dialogue model}
	
	\label{sec:dialogue-model}
	
	The goal of a negotiation is to choose an option in a set of possible options $\mathcal{O}$. Each option $o\in\mathcal{O}$ is defined as a set of values $\{v_1, ..., v_n\}$ associated to criteria $\{C_1, ..., C_n\}$ that reflect the option's characteristics.  
	For instance, in a negotiation about restaurants, the criteria might be the type of cuisine and the price, we could have the option: $(French,Expensive)$.
	
	The agent is provided with a set of partial or total ordered preferences $\prec_i$ defined for each criterion $C_i$. Using theses preferences, the agent can compute a score of satisfaction $sat(v)$ for each value of each criterion. The satisfaction of a value $v \in C_i$ is computed as the number of values that the agent prefers less in the preferences order $\prec_i$. The notion of satisfaction represents the score of liking for the value. The closer the satisfaction of a value $v$ gets to 1, the more the agent likes $v$.
	 
	 
	For example, let's consider the criteria of $cuisine$ defined with the following values: $\{$\emph{french, italian, japanese, chinese}$\}$. In addition, the agent has a total order of preferences on these values $ \prec_{cuisine}= \{chinese \prec japanese, japanese \prec italian, italian \prec french\}$. Based on this order of preferences $\prec_{cuisine}$, the agent is able to compute the value of satisfiability associated to each value as presented in table \ref{tab:sat}.
	
	\begin{table} [h]
		\centering
		\begin{tabular}{ |c|c|c|c|c| }
		\hline
		value & chinese & japanese & italian & french \\	
		\hline
		sat(value) & 0 & 0.3 & 0.6 & 1 \\
		\hline
	\end{tabular}
		\caption{$Sat$ computed on the set of preferences $\prec_{cuisine}$.}
		\label{tab:sat}
		\vspace{-0.5em} 
	\end{table}

	
	%, then, the score is normalized in $[0, 1]$: 
	
	%	\begin{equation}
	%	sat(v, \prec_i) =	1 - \left( \frac{|\{v' : v' \neq v \  \wedge \ (v \prec_i v')\}| }{( |C_i| - 1 )}\right)
	%	\end{equation}
	%	

	
%	\par For example, let us consider a criteria with 4 possible values $\{A, B, C, D\}$ and the set of preferences $\{A \prec B, C \prec D , B \prec D \}$. The values of satisfiability are depicted in the table \ref{tab:sat}.
%%	\begin{table}
%		\centering
%		\begin{tabular}{ |c|c|c|c|c| }
%			\hline				
%			value & A & B & C & D \\
%			\hline
%			
%			\hline
%			sat(value) & 0.3 & 0.6 & 0.6 & 1 \\
%			\hline
%			
%		\end{tabular}
%		\caption{Value of satisfiability for the model $\{A \prec B, C \prec D , B \prec D \}$.}
%		\label{tab:sat}
%	\end{table}
	
	The domain of negotiation includes a \emph{communication model}. This model enables the agent to communicate with its partner throughout text based \textit{utterances}. 
	Each one is associated with a natural language formulation. The details are presented in \cite{ouali2017computational}.
	
	To keep the model as generic as possible, we defined five utterances types grouped in three different categories. \textbf{Information moves} (\textit{AskValue/AskCriterion} and \textit{StateValue}) are used to exchange information about the participant's likings. They are used to express what the agent likes or do not like (\emph{e.g} \textit{I (don't)like Chinese restaurants}).
	\textbf{Negotiation moves} (\textit{Propose}, \textit{Accept} and \textit{Reject}) allow the agent to make or to answer to proposals. The agent can propose, accept and reject, both values (``Let's go to a Chinese restaurant'') or options (``Let's go to \emph{Chez Francis}'').	
	\textbf{Closure moves} (\textit{NegotiationSuccess} or \textit{NegotiationFailure}) are used to end the dialogue.

	
	\subsection{Decision based on power}
	\label{sec:dec}
	The decision making process is designed to consider, in addition to preferences, the power of the agent as presented in the \textit{step 1} of the figure \ref{fig:schema-general}. 
	Therefore, the agent is initiated with a value of power $pow \in [0,1]$. 
	
	We present in this section, the decisional model, which relies on three elements. We will explain how the principles of power inspired from social psychology literature influence this decisional process.

	
	\subsubsection{Satisfiability}
	\label{sec:sat}
	The value of satisfiability is associated to the \emph{StatePreference(v)} utterance that allows the agent to express his likings. As showed by \cite{de1995impact}, high-power negotiators are more demanding than low-power ones.
	We capture this principle by implementing a set of the agent's satisfiable values, named $S$, that varies depending on the level of power $pow$. It is computed as follows:

	\begin{equation}
		\forall v,\hspace{2mm} v\in S\hspace{2mm}\mathrm{iff}\hspace{2mm}sat(v) \geq pow
	\end{equation}
	
	For example, if we consider the preference set $\prec_{cuisine}$ whose values of satisfiability are given on table~\ref{tab:sat}. Let's now consider a first agent Bob with a value of power $pow = 0.7$. We can compute, using the above function, that bob likes only $french$ cuisine. Whereas, the second agent Arthur with a smaller value of power $pow=0.4$ will have its set of satisfiable values initiated to $S= \{french, italian\}$. 
	
    This set $S$ is used directly to compute the values of \emph{StatePreference} utterances.
	
	\subsubsection{Acceptability}
	
	In collaborative negotiation, both negotiators might have to reduce their level of demand over time because they want to reach an agreement. The level of concessions expressed in a negotiation is affected by power. It was demonstrated that low-power negotiator's demand decrease over time and tends to make larger concessions than high-power negotiator \cite{de1995impact}.
	
	We designed a function that decreases the agent level's of demand during the negotiation, specifically, when the negotiation is not converging.  To model this behavior, we use a \emph{concession curve}, named $self(t)$ . %and illustrated in Figure \ref{fig:conc}.
	We define this function to be a time varying function of $pow$ which decreases over time $t$ and follows the concession curve. In the beginning, $self(0) = pow$ and when the negotiation evolves without converging, the function decreases as illustrated in the figure \ref{fig:conc}.
	
	
	\begin{floatingfigure}[l]{1.3in}
		\captionsetup{justification=centering}
		\includegraphics[width=1.2in]{figs/sv3.png}
		\caption{\label{fig:conc}Concession curve}
	\end{floatingfigure} 
	
	
	This function is designed to evaluate the acceptability of a proposal. Indeed, during the process of negotiation, the agent makes decisions about the proposals it receives by its partner. It might express an \emph{Accept} or \emph{Reject}. In the case where the negotiation is not converging, the agent has to lower his level of demand and makes concessions. Therefore, the agent uses the value of $self$ to directly answer a \emph{Propose(v)} utterance. We say that the value $v$ is \emph{acceptable} at time $t$, and we note $v \in Ac$, when:
	\begin{equation}
	v\in Ac\hspace{2mm}\mathrm{iff}\hspace{2mm}sat(v) \geq self(t)
	\end{equation}
	
	The agent will answer with an \emph{Accept} to a proposal only if the value is acceptable, and will answer with a \emph{Reject} otherwise. Also note that, when building proposals (i.e. \emph{Propose} utterances) the agent can only propose a value that is acceptable.
	
	Finally, it is important to note that the set $Ac$ grows over time: as the negotiation evolves, the agent might accept proposals which are not satisfiable, as a consequence of making concessions. We denote $M\subsetneq Ac$ the set of not-satisfiable values that can became acceptable due to concessions: $M = Ac\setminus S$.

	
	
	\subsubsection{Lead of the dialogue}
	De Dreu \textit{et al} showed that the participant with higher power tends to lead the dialogue and to focus on the negotiation convergence \cite{magee2007power,de2004influence}. On the opposite, low power negotiators focus on building an accurate model of their partner's preferences in order to make the fairest decision \cite{de1995impact}. This leads them to ask more questions about other preferences
	
	In our model, this means that agents with high values of power ($pow>0.5$) will select \emph{Propose} moves more often. Indeed, to make the negotiation converge, the agent has to keep making proposals until a compromise that satisfies the agent and its partner is found.
	On the contrary, agents with low power will select \emph{AskPreferences} utterances more often to collect information. A detailed presentation of the utterance selection is presented in \cite{ouali2017computational}.
	
		\begin{table}[ht]
			\centering
			\caption{Applicability conditions for the five utterance types.}
			\label{tab:utt}
			\begin{tabular}  {|l|l|}
				\hline
				Utterance & Applicability condition \\
				\hline
				AskPreference(v) & None \\
				\hline 
				StatePreference(v) & $v\in S$ \\
				\hline 
				Propose(v) & $v\in Ac$ \\
				\hline
				Accept(v)  & $v\in Ac$ \\
				\hline
				Reject(v) & $v\notin Ac$ \\
				\hline
			\end{tabular}
		\end{table}
		
	
	\subsubsection{Summary}	
	The result of the decision process is the utterance that the agent communicates to the user (see \textit{step 2} of the figure \ref{fig:schema-general}). Thus, table~\ref{tab:utt} presents the applicability condition for the five utterance types, based on the values of $pow$ and the derived sets $S$ and $Ac$. The utterance \emph{AskPreference} only depends on the lead of dialogue rules, related to the value of $pow$.

	\section{Beliefs about other: general algorithm}

	In order to build a complementary relation of dominance with the user, the agent must adapt its behavior to complement the behaviors of the user. To this due, the agent has to evaluate the power of the user, as presented in figure \ref{fig:schema-general}.
	
	In order to figure out the value of power expressed by the user, the agent has to understand the decisional model of the user. To this goal, we propose to use a Theory of Mind (ToM) approach \cite{premack1978does} based on simulation (\emph{ST}) to establish and maintain representations of the mental states of its human counterpart. 
	The mental state requires to model the inputs necessary to reason during the negotiation. The idea is to consider different hypotheses about the user's mental state, including his/her value of power and its preferences. Using the agent's decision model, we simulate the possible utterances produced by each hypothesis. 
	We then compare the results of this simulation with the actual utterance expressed by the user ($Utterance_{other}$) in \textit{step 3}. This gives information about the possible values of power. The principle is illustrated on Figure~\ref{fig:tom}.
	
%	\begin{figure*}
%		\centering
%		\includegraphics[width=0.8\linewidth]{figs/tom.png}
%		\caption{A theory of mind approach to evaluate the user's level of dominance} 
%		\label{fig:tom}
%	\end{figure*} 
	
	This approach however relies on a couple of strong assumptions. First, it assumes that the decision model is an accurate representation of the decisional process of the user. There is no way to guarantee this assumption. However, in our previous research \cite{ouali2017computational}, we showed that the behaviors of power expressed by agents are correctly perceived by human users. 
	%This is no proof that the model is similar to a human decision process, but the behaviors that it produces are at least coherent with the notion of dominance as human people understand it.
	
	The second assumption is that the system can build a model of the possible mental states of the interlocutor. Concretely, this means a value of $pow$ and a set of preferences $\prec_i$ for all criteria. 
	
	Based on these assumptions, we present the general algorithm of the user's model of mental state as follows:
	\begin{enumerate}
		\item Build a set $H_{pow}$ of hypothesis about power: $h\in H_{pow}$ represents the hypothesis $pow=h$. In our work, we consider only 9 values: 
		
		$H_{pow}=\{0.1, 0.2, \ldots, 0.9\}$.
		\item For each hypothesis $h$, build the set of all possible preferences $Prec_h$: the elements $p\in Prec_h$ are partial orders on the criteria.
		\item After each user utterance $u$, remove all elements in $Prec_h$ that are not compatible with $u$. Concretely, if the applicability condition of $u$ is not satisfied in $p\in Prec_h$, then $p$ must be removed from the candidate mental states.
		\item For each $h$, generate the corresponding utterance using $h$ as input for the decisional model.
		\item compute a score $score(h)$ based on the size of remaining hypothesis $|Prec_h|$ that generate an output similar to the utterance, $Utterance_{other}$, enunciated bu the user. 
		\item 	The idea is that the hypothesis with the highest score is the most probable value for the user's power value.
		\vspace{-0.1 cm}
		\begin{equation}
		pow_{other} = \operatorname*{arg\,max}_{h} (score(h))
		\vspace{-0.15 cm}
		\end{equation}
		
	\end{enumerate}
	


	
	\subsection{Simulation of the other's preferences}
	
		The representation of the user's preferences is a crucial input for the decisional model. In order to generate the set of possible preferences for each hypothesis, we need to consider all possible partial orders $\prec_i$ for each criterion $C_i$. 
		We can compute the size of the set of binary preferences based on the number of values, which is $(|C_i| + 1)!$ possible partial orders for each criteria. As a consequence, for a topic with $n$ criteria, there are $\prod_{i=1}^n (|C_i|+1)!$ different possible preference sets.
	
		If we consider a reasonable example, with 5 criteria. For each criteria, we consider approximatively 4 to 10 possible values each. The set of possible preferences that the agent has represent for the user's model, are between $24.10^9$ and $100.10^{36}$ possible preference sets. 
		We can easily conclude that it is not reasonable to consider all theses hypotheses, one by one, at each step of the dialogue.
	
%		Even if we consider only total order sets of preferences, we still have  $\prod_{i=1}^n |C_i|!$ possible sets. It remains impossible to consider in the context of a dialogue.
	
	%	Moreover, our goal is not to model the exact mental state of the interlocutor. We only want to evaluate his/her behavior of power. In the proposed ToM approach, we need to make hypothesis on the preferences to compute the applicability conditions of the utterances. The system uses the preferences to evaluate which values are satisfiable ($S$) or acceptable ($Ac$), depending on the value of $pow$ and the current progress of the negotiation. But the preference set $Pref_h$ contains too much information! What is really required to simulate the decision process are only the sets $S$ and $Ac$, as shown on table~\ref{tab:utt}.
	
	%	This said, it becomes visible that, when simulating the other's decision, what really matters is whether the discussed value is satisfiable or acceptable (depending on the utterance), not its exact position in the preference set. As a consequence, our proposal to reduce this complexity is to consider unordered sets for $S$ and $Ac$ in our hypothesis, and to assume we have total order sets. This drastically reduces the size of the hypotheses.
		We conducted an analysis of our decisional model to define the need of preferences. As presented in section \ref{sec:dec}, the preferences are used to compute the \emph{satisfiability} of each value. %The value of \emph{satisfiability}
		 This value is necessary during the decisional process because it is required to build the set of satisfiable values $S$, and the set of acceptable values $Ac$.   
	
		However, in the case of total ordered preferences, all the values are comparable, which means that they can be sorted by order of preferences, by calculating the number of predecessors, as in the example \ref{tab:sat}. Independently from the values themselves, by knowing the number of values, we can compute the value of \emph{satisfiability} of each value only from its rank of this in the order of preferences. For example, if we define a different set of preferences  on the criterion $cuisine$ $\prec'_{cuisine} = \{italian \prec japanese, japanese \prec french, french \prec chinese\}$. We will, still obtain similar values of satisfiability. The score of satisfiability for each value is directly computed from the number of predecessor in the ranking as presented on Table~\ref{tab:poss}. Therefore, in a total ordered preferences, we will always obtain the same values of satisfiability as presented in the table \ref{tab:poss}. 
	\begin{table}[h]
		\caption{Satisfiability depending on the rank for a 4-values criterion.}
		\label{tab:poss}
		\centering
		\begin{tabular}{ |c|c|c|c|c| }
			\hline				
			rank(value) & 1 & 2 & 3 & 4 \\
			\hline
			Nb predecessors & 3 & 2 & 1& 0 \\
			\hline
			$sat(value)$ & 0 & 0.33 & 0.66 &1 \\
			\hline
		\end{tabular}
	\end{table}
	
	As a consequence, for a given value of power $pow$, we can compute the number of satisfiable values $S$ without knowing the relation of preferences. For example, for the criterion $cuisine$ which have 4 values, for any given total ordered preference, and a value of $pow = 0.4$, we can deduct that the number of satisfiable values is always $|S| = 2$
	
	Instead of calculating all the possible relation of preferences $\prec$. We can reduce the calculation to the set of possible satisfiable values.  Concretely, consider a criterion with $n$ number of values and total ordered preferences. For a given value of power $pow$, we obtain, $s$  the size of $S$. We have to generate only $\binom{n}{s}$ possibilities for the values of $S$ to consider. For example, for the criterion $cuisine$ and $pow =0.4$, we can generate all the possible satisfiable values as illustrated in table \ref{tab:sat_poss}.
		\begin{table*}[h]
			\centering
			\caption{The possible $S$ for $cuisine$, with $pow=0.4$}
			\label{tab:sat_poss}

			\begin{tabular}{|p{1.9cm}|p{2.25cm}|p{2cm}|p{2.25cm}|p{2cm}|p{2.25cm}| }
				\hline				
				 $S_1$ & $S_2$ & $S_3$ & $S_4$ & $S_5$ & $S_6$ \\
				\hline$(italian,french)$& $(italian,japanese)$ & $(italian,chinese)$ & $(french,japanese)$ & $(french,chinese)$ & $(japanese,chinese)$ \\
				\hline
			\end{tabular}
		\end{table*}
	
	This representation allows our model of the other to work with a reasonable set of hypotheses.  
	However, simulating the behavior of the interlocutor with incomplete knowledge has two consequences. First, it requires to adapt the simulation model of the decision making to deal with the non-ordered sets of satisfiable and acceptable values. Second, it might affect the precision of the prediction of the interlocutor's power.
	We present in the next section the partial model of preferences and the adaptation of the decisional model.
	
	\section{Partial model of preferences}
			\colorbox{red}{In order to simulate another’s mental processes,
		it is not necessary to categorize all the beliefs and
		desires attributed to that person as such. In other words, it
		is not necessary to be capable of complete introspection %http://ii.tudelft.nl/~maaike/papers/Iat_2009.pdf
	}
	
	In order to generate theses hypotheses for any criterion, we make the strong assumption that preferences are \emph{total ordered}. In this case, all the values are comparable and could be ranked by order of preferences. Knowing the rank of preferences allows the agent to compute in advance the possible values of satisfiability.
	
	Based on the values of satisfiability, and given a fixed value of $h \in H_{pow}$, we compute the value $s$ which is the size of all our hypotheses $S$ for this value of power. We then built all possible combinations of satisfiable values  noted $M_h$. For example, considering a value of $pow =0.6$, and the preference model given on Table~\ref{tab:sat} for our 4-values criterion. The number of satisfiable values $s=2$. We can build $M_{0.6} = \{(A,B), (A,C), (A,D), (B,C), (B,D), (C,D)\}$. This process is generalized to all the hypotheses of $H_{pow}$, as presented on Table~\ref{tab:sat}
	
	\begin{table}[h]
		\centering
		\caption{Hypotheses on mental states for a 4-value criterion $C_i=\{A, B, C, D\}$}
		\begin{tabular}{ |c|c|c| }
			\hline
			& \multicolumn{2}{c|}{Hypotheses}  \\
			\hline
			Hypothesis & $pow$ & $M_{pow}$ \\
			\hline
			H1&0.3&$\{ (A,B,C) , (A,B,D), (A,C,D), (B,C,D) \}$ \\
			\hline
			H2&0.4&$\{ (A,B), (A,C), (A,D), (B,C), (B,D), (C,D) \}$ \\
			\hline
			H3&0.5&$\{ (A,B), (A,C), (A,D), (B,C), (B,D), (C,D) \}$\\
			\hline
			H4&0.6&$\{ (A,B), (A,C), (A,D), (B,C), (B,D), (C,D) \}$ \\
			\hline
			H5&0.7&$\{ (A), (B), (C), (D) \}$\\
			\hline
			H6&0.8&$\{ (A), (B), (C), (D) \}$ \\
			\hline
			H7&0.9&$\{ (A), (B), (C), (D) \}$ \\
			\hline
		\end{tabular}
		
		\label{table:poss}
	\end{table}
	
	\subsection{Decision in negotiation with partial representation of preferences}
	The adaptation of the mental state to partial representation implies to modify the reasoning process. In the following, we present the adaptation of the decisional model to take into account partial and incomplete mental state. The goal is to reproduce the reasoning model in order to compute at each turn, the power $other_{pow}$ of the interlocutor. 
	
	First, we present the adaptation of the functionalities. Second, we present, the computation of the other's \emph{pow} from functions of decision.   
	
	\subsubsection{Satisfiability:}
	To compute whether a value $v \in C_i$ is satisfiable, we check for each hypothesis of power $h_i$, the set satisfiable values $S_i \in M_h(pow)$.
	Thus: 
	\begin{equation}
	sat_{S_i}(v)= \left\{\begin{array}{ll}
	True	 & \mathrm{if\ }  v \in S_i\\
	False & \mathrm{otherwise}
	\end{array}\right.
	\end{equation}
	
	\subsubsection{Acceptability:}
	Computing the acceptability of a value $v$ depends on the current of value of $self(t)$. For each hypothesis on power $h_i$, we associate a value $self_i(t)$ that represents the level of concessions at the current time. 
	
	With partial knowledge of preferences and for a fixed value of power $h_i$, the agent is not able to compute all the acceptable values $Ac_i$. Especially,   values of the set $M_i$ (\emph{i.e} acceptable values which are not satisfiable). 
	
	Nevertheless, the agent can have certain information about acceptable values such as $ S_i \subset Ac_i$. Moreover, using the initial values of satisfiability for a given criterion (see table \ref{sat}), agent can compute the number of acceptable values at the current state of the negotiation $|Acc_i|$ and by consequences $|M| = |Acc_i| - |S_i|$. 
	
	We propose to calculate the score of acceptability of a value $v$ taking into account the available information. Therefore, for a hypothesis of power $h_i$, hypotheses on preferences $S_i \in M_h(h_i)$,  and the list of accepted values during the negotiation $A$, the score that $v \in D$ is acceptable is computed as follow: 
	\begin{equation}
	Acc(v, pow) = C_{|D|-(|S_i| + k)}^{|M| - k}
	\end{equation}
	$k = |K| $ is the number of elements in the set $K = A \cap \overline S_i$
	
	
	\subsubsection{Lead of the dialogue}		
	As presented before, the choice of a specific utterance's type translates behaviors of power. Indeed, a high frequency of choosing \emph{proposal utterance} shows a behaviors of high-power. Whereas, a high frequency of \emph{share preferences utterances} reflects behaviors of low-power.
	We note $history$ the list of utterances enunciated by the user. the value of power is computed from the ratio of propose enunciated versus asks.
	\begin{equation}
	pow_{other} = \left\{\begin{array}{ll}
	> 0.5 & \mathrm{if } \frac{history(Propose)}{hisotry} > 0.5\\
	\leq 0.5 & \mathrm{if  } \frac{history(Ask)}{hisotry} > 0.5
	\end{array}\right.
	\end{equation}
	
	Once, the list of possible is restricted, we update the hypotheses by taking into account the value associated to the expressed utterance.
	
	\subsubsection{Share a preference}
	When the user expresses a \emph{StatePreference(v, s)}, he shares his preferences in the way where $v \in S$ if $s =true$, otherwise $v \notin S$. 
	In addition, when the user rejects a proposal \emph{Reject(p)}, he also shares his preferences . As $S \subset Acc$ means if a value is not acceptable, it is automatically not satisfiable $p \notin S$. 
	
	Therefore, for each  $h_i \in H_{pow}$, we propose to update the agent's hypotheses $M_h(h_i)$ by removing all the hypotheses on preferences that are no longer consistent with the information learned. 
	Then, we compute the score of each $h_i$ at the moment $t$ :
	
	$$score(h_i,t) = \frac{|M_h(h_i, t)|}{|M_h(h_i, init)|}$$
	
	
	\subsubsection{Accept a proposal}
	When the user accept (\emph{Accept(p)}) or propose a proposal (\emph{Propose(p)}), means that $p \in Acc$. 
	The agent has to calculate for each $h_i \in H_{pow}$ the score of acceptability. In addition, the values of acceptability have to be normalized to allow a coherent comparison. Thus, given a hypothesis on power $h_i$, he score of acceptability is normalized by taking into account the ideal score of acceptability.
	
	$$I_{pow} =  C_{|D|-|S_i|}^{|M|}$$
	
	
	The final value of acceptability is then:
	\begin{equation}
	score(h_i, t)= \left( \begin{array}{c}  \frac{1}{I_{pow}} \cdot \sum_{S_i \in M_h(h_i) } acc(p, h_i) 
	\end{array}\right) \frac{1}{| M_h(h_i)|}
	\end{equation}
	
	\subsection{ToM algorithme with partial preferences}
	At each turn of the dialogue, the agent uses its model of the theory of mind in order to compute other's behaviors of power $pow_{other}$. We present, the process of updating $other_{pow}$ depending on the received utterance. 
	
	The value of power selected:
	\begin{equation}
	pow_{other} = \operatorname*{arg\,max}_{h_i \in H_{pow}} ( score(h_i,t))
	\end{equation}
	
	
	% -----------
	\section{Evaluation}
	In order to assess the validity of our partial model of preferences for the prediction of the interlocutor's power, we propose to simulate dialogues with two artificial agents. We can then compare the result of the prediction with the actual mental model of the interlocutor. We do not only evaluate the accuracy of our model of theory of mind, but also how fast it can predict the power of the interlocutor as well as the timeliness of the algorithm.
	
	\subsection{Method}
	We implemented two agents with theory of mind abilities.
	The first agent ($agent_A$) plays a role of a dominant agent( $pow > 0.5$), whereas, the second agent ($agent_B$) plays the role of a submissive agent ($pow \leq 0.5$). 
	We manipulated two simulation parameters for the initialization of our agents. First, the power of both agents (named \emph{pow-a} and \emph{pow-b}). We variate the values of power in order to study the accuracy of predictions in different settings as presented in table \ref{tab:powsettings}.
	\begin{table}[t]
		\centering
		\caption{Initial condition's setting for the values of power} 
		\begin{tabular}{|l|cccc|}
			\hline 
			\textbf{Dominance value } &	\multicolumn{4}{c|}{ Initial values of power } \\
			\hline
			Dominant agent $pow_A$ & 0.3 & 0.4 & 0.5 &  \\
			\hline
			Submissive agent $pow_B$ & 0.6 & 0.7 & 0.8 & 0.9\\
			\hline
		\end{tabular}
		
		\label{tab:powsettings}
	\end{table}
	
	Second, we variate the size of preference sets and more specifically the size of the discussed topic in order to study the timeliness of the algorithm from simple to richer topics. We generate three types of topics as presented in table \ref{tab:initP} and for each topic we generated $50$ different models of preferences. In total, negotiators was initiated with $150$ different models of preferences, added to the values of power,  $1451$ combinations were created for the initial states of both agents. For each combination, we generate a dialogue in which the agent with theory of mind estimates the other's value of power.
	
	
	\begin{table}[]
		\caption{Initial condition's setting for the preferences set} 
		\centering
		\begin{tabular}{|p{1.75cm}|p{1.5cm}|p{1.75cm}|p{1.5cm}|}
			\hline 
			\textbf{Preference's name } & Number of criteria & Average number of values/criterion & Possible $M_h$\\
			\hline
			Small & 4 & 3 & 1296 \\
			\hline
			Medium & 4 & 4 & 4.14 E$^5$ \\
			\hline
			large & 4 & 10 & 2.6 E$^9$ \\
			\hline
		\end{tabular}
		
		\label{tab:initP}
	\end{table}
	
	\subsection{Results and discussion}
	We present in this section the results obtained for both the accuracy of predictions made by our model and the timeliness of the execution.
	
	\subsubsection{Accuracy of predictions:} For each dialogue, we obtain the predictions made by the agent with ToM abilities about the behaviors of power of the other agent. Results are summarized in table \ref{tab:res1}. 
	
	
	First, we computed the \emph{standard deviation} between the guessed value of power $Other_{pow}$ and the actual value of power $pow$. In average, for the total of $1451$ dialogues, a small deviation of $0.075$ was observed. Moreover, in order to analyze the results in a more general way, we calculated the \emph{residual deviation }  that computes the accuracy of the dependent variable being measured. We have computed the deviation of prediction between the predicted value  $Other_{pow}$ from the real value of power $pow$. 
	We observe deviations of the range $rv = 0.015$ which means that our model makes accurate and close predictions of other's power.
	
	
	\begin{table}[h]
		\centering
		\caption{Results of margin errors for prediction} 
		\begin{tabular}{|l|c|}
			\hline
			Average of the standard deviation & 0,075 \\
			\hline
			Residual variation (rv) & 0,015 \\
			\hline
		\end{tabular}
		
		\label{tab:res1}
	\end{table}
	
	Second, we analyzed the frequency of false predictions. For example, $agent_A$ predicts that $agent_B$ is dominant whereas $agent_B$ is submissive. To this end, we computed the percentage of false predictions. For all the dialogues, only $30$ predictions were incorrect which means that $ 2.6 \% $ of predictions were false. This result confirm the reliability of our algorithm. 
	\begin{table*}[t]
		\begin{tabular}{|c|c|c|}
			\hline
			\multicolumn{3}{|c|}{Number of etiration to make predictions} \\
			\hline
			Good predictions & $rv \leq 0.02$ & Best prediction \\
			\hline
			2.53 & 3.25 & 3.79\\
			\hline
		\end{tabular}
		\caption{Average number of iterations to compute a prediction} 
		\label{tab:conv}
	\end{table*}
	Finally, for all the dialogues in which the agent was able to find a good prediction (in total $1421$), we analyzed the rapidity of convergence of our algorithm. The results are presented in table \ref{tab:conv}
	
	
	For each dialogue, we computed the number of iteration necessary to find a good prediction. In average, the algorithm needed $3$ iterations in order to predict the right range of dominance of the other (weather the agent has dominant or a submissive behavior). 
	
	Moreover, we calculated the average number of iterations needed to find a prediction such that $rv \leq 0.02$. In average the agent needed $3$ iterations in order to evaluate a close value to the other's power. The evolution of convergence for all the dialogues are presented in figure  \ref{fig:converge}
	
	We  also computed the average number of iterations in order to find the best prediction of $Other_{pow}$. The results depicted in table \ref{tab:conv} show that the agent makes in average $4$ iterations to converge towards the best value.  
	
	%		\begin{table*}[t]
	%		\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|}
	%			\hline
	%			\textbf{$Other_{pow}$} & \multicolumn{9}{c|}{Number of iteration } \\
	%			\hline
	%			Small &0,047&0,071&0,063&0,016&0,010&0,009&0,011&0,011&0,011 \\
	%			\hline
	%			Medium&0,058&0,084&0,075&0,030&0,017&0,016&0,017&0,017&0,017\\
	%			\hline
	%			Large&0,052&0,116&0,099&0,024&0,015&0,015&0,017&0,017&0,018 \\
	%			\hline
	%			
	%		\end{tabular}
	%		\caption{Results of margin errors for prediction} 
	%		\label{tab:conv}
	%	\end{table*}
	
	We studied the impact of the initial number of hypotheses about the other model on the convergence of the algorithm. We wanted to study weather a large number of hypotheses will need extra iterations to converge. Therefore, we compared results obtained for small topic, medium, and large topics of negotiation. The graph presented in figure \ref{fig:converge} shows that our algorithm converges in average quickly independently from the size of topic. We can observe that the algorithm took two additional iterations to converge in the large topic. The difference is not significant to affect the general behavior of our model.
	%	\begin{table}
	%		\
	%		\begin{tabular}{|p{3 cm}|c|c|c|}
	%			\hline
	%			Model size & Small & Medium & Large \\
	%			\hline
	%			Time execution (milliseconds) & 50.28 &	59.83 &	116.38\\
	%			\hline
	%		\end{tabular}
	%	\end{table}
	
	\begin{figure}[]
		\fbox{\includegraphics[width=\linewidth]{figs/total}}
		\caption{Algorithm convergence for all topics} 
		\label{fig:converge}
	\end{figure}
	
	
	\subsection{Timeliness}
	We evaluate the time execution of the algorithm in order to study how the model of theory of mind evolves.For each dialogue, we computed the the average time execution at each negotiation turn. We aim to study the effect of hypotheses's size on the rapidity of prediction at eahc turn. Results are presented in figure \ref{fig:time}. When comparing the time execution between the medium and large models, we observe that the algorithm took in average $12$ milliseconds at each turn. However, this difference is not significant since the total execution remains very quick.
	
	\begin{figure}[]
		\fbox{\includegraphics[width=\linewidth]{figs/time_exec.png}}
		\caption{Algorithm convergence for all topics} 
		\label{fig:time}
	\end{figure}
	
	We analyzed the behaviors of our model of ToM in different aspects and the obtained results provide a strong support to its accuracy. Indeed, for most of the generated dialogues, the agent with ToM abilities was able to evaluate a very close approximation of its partner's level of power. Moreover, the agent was able to find the right dominance range only after two dialogue turns and the best evaluation after five turns. Theses behaviors were generated in a reasonable amount of time allowing the agent to produce real time dialogues.
	
	These findings strengthen the accuracy of our model and give good perspectives to implement this model in the context of human/ agent collaborative negotiation. However, the presented validation in the context of agent/agent negotiation is a controlled evaluation since both agents use the same decisional model. This situation increases the chance of good predictions of the partner's behaviors of power. 	Thus, a validation of our collaborative model of negotiation must be validated in the context of human/agent negotiation.
	\section{Conclusion}
	We presented in this paper, a model of collaborative negotiation with theory of mind (ToM) abilities. Our model of ToM focuses essentially to predict the agent's partner value of power in the perspective of defining a complementary relation of dominance.
	
	The agent builds partial representation of the mental state of its partner, allowing the agent to have sufficient knowledge to compute the value of the partner's power. In addition, the limited knowledge ensure the agent to reason in a reasonable time to produce real time dialogues.
	
	Our model was evaluated and validated in the context of agent/agent negotiation. The results confirmed the accuracy of the ToM models. Indeed, the agent was able to generate close and quick predictions of it's partner behaviors in several conditions.
	
	The presented evaluation relies on the fact that both agents use the same decision to build their strategy in  the negotiation. However, in the context oh human/agent negotiation, the agent doesn't know the decisional model of the user. We only make the assumption that the user uses the same reasoning as the agent.
	%Rappeler l'importance de la complementarite
	Therefore as perspective, we aim to evaluate the accuracy of our model in the human/user negotiations. Moreover, the agent will also adapt its behaviors of power to complement the predicted user's behaviors in order to simulate the dominance complementarity. In such situation, the agent will have to consider the effect of wrong predictions on the negotiation outcomes. We believe that modeling a complementary relation of dominance will improve the negotiation outcomes and increase mutual liking between the agent and the user.
	
	\bibliographystyle{IEEEtran}
	% argument is your BibTeX string definitions and bibliography database(s)
	\bibliography{IEEEabrv,bibliography}
	%
	% <OR> manually copy in the resultant .bbl file
	% set second argument of \begin to the number of references
	% (used to reserve space for the reference number labels box)
	
	
	
	
	
	% that's all folks
	\end{document}
	
	
