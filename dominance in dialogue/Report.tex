\documentclass{llncs}
\usepackage[noend]{algpseudocode}
\usepackage{subcaption}
\usepackage{subfig} 
\usepackage{usual}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{eulervm}
\usepackage{fontenc}
\pagenumbering{alph}

\usepackage[rflt]{floatflt}
%\pagestyle{plain}
%
\begin{document}
\title{  \vskip -10pt}

\author{Lydia Ould Ouali\inst{1}, Charles Rich\inst{2} \and
Nicolas Sabouret\inst{1} }

\institute{LIMSI-CNRS, UPR 3251, Orsay, France \\
Universit\'e Paris-Sud, Orsay, France \\
\email{\{ouldouali, nicolas.sabouret\}@limsi.fr}
\and
Worcester Polytechnic Institute\\ Worcester, Massachusetts, USA\\
\email{rich@wpi.edu}
}
\maketitle 

\section{Interpersonal relationship}
Social relationship and its effects on behavior lies at the heart of social science. It was proved that understanding interpersonal relationship is crucial for social cognition \cite{reis2000relationship}. Most of the literature that get interested in the conceptual analysis of interpersonal relationship have agreed that the essence of relationship appears in the nature of interaction that occurs between relationship partners. Moreover, social relationship is a dynamic ssorasorystem that may develop and change continuously over interactions \cite{reis2000relationship,svennevig2000getting}.
Communication between relationship partner will grow in stages from the initial interaction where partners share superficial information to a more deeper relationship where partners can share more personal information. Therefore, the social relationship of partners affects their behavior and their strategy of dialogue.

\section{Representation of interpersonal relationship}

The aim of this section is to relate the work of N.HASLAM \cite{haslam1994mental} who get interested on the mental representation of social relationship. In summary, there are three different representation in the literature. 
\par The first is the dimensional representation. It is the most common representation that consists on represent relationships in a dimensional circle (c.f wiggins model). Therefore, any relationship can be situated and valuated  in this  \textit{continuous} dimensional space. 

The second representation is the lawful representation. Laws are defined in the same circle's dimension of affiliation and control. The main difference with the dimensional representation is that laws try to make discrete prediction about the other behavior. For each behavior, complementarity and symmetry make discontinuous prediction about the the other interact behavior. 

Finally, categorical representation  make a discrete prediction on which kind of social relationship are well performed. In addition the categorical representation focus only on local prediction ( prediction in a small region within a dimensional scheme).

\begin{tabular}{|c|c|c|}
  \hline
  Dimensions & Laws & Categories \\
  \hline
  	Continuous &   discontinuous   &   discontinuous  \\
 	Local & Global & Local\\
  \hline
\end{tabular}

\subsection{Dimensions of interpersonal relationship}
The definition of dimensions was widely studied under different labels. However, we distinguish four dimensions that are always used for the representation of interpersonal relationship. 
\subsubsection{Dominance and power}
Scholars from different fields converge to define power as the ability to influence the other behavior \cite{svennevig2000getting}. Power may be latent (Komter, 1989), which is in contrast with the definition of dominance which is inevitably manifest (Dunber, 2004). It is an asymmetric variable in which one interactant's assertion of control is met by acquiescence from another (Rogers-Millar \& Millar, 1979). 
\subsubsection{Familiarity}
In Svennevig’s relational model \cite{svennevig2000getting}, the definition of familiarity is based on social penetration theory (Berscheid and Reis, 1998) which describe the grades of relationship evolution through mutual exchange of information both in depth (superficial information to personal and intimate information) and breadth(from narrow to a broad range of personal topic).   
\subsubsection{Affect}
This dimension represent the degree of liking that have one interact for the other. This dimension allows interactants to create personal attachment and improve the relationship of interactants \cite{nicholson2001role}
\subsubsection{Solidarity}
The solidarity dimension is in the opposite of power dimension. It is a symmetrical dimension where two individuals share equal obligations and rights \cite{svennevig2000getting}. Is is identified as ‘like-mindedness’ \cite{bickmore2005establishing} where interactants have the same behaviors and share for example the same preferences.
\subsection{Dialogue utterances}
In this paper we are interested in  modeling a collaborative negotiation on preferences in the context of social dialogue. The negotiation takes its values during the dialogue when messages are exchanged between interlocutors. In the following we present our model of dialogue.
\subsubsection{Structure of messages}
The basis structure of dialogue is a message that contain all the information that interlocutors exchange. We thus define a message as triple \emph{M = $\textless i \rightarrow j, s(cont), F  \textgreater$}, where \emph{i, j}$\in$ \{agent, user\} are the agents participating in the dialogue,\emph{s $\in \wp$}  is the utterance used to express a message. $\wp = \{ Ask, Propose, Reject, Accept, State\}$  represents the set of utterance types \cite{searle1969speech} that agents can express to exchange messages. 
 $F \in \Im $  where $\Im = \{ Strongly, Weakly, Yelling, With hesitation ...\}$ is a set of verbal and non verbal style features that are applied to the utterance to express a personal linguistic style or social move. These features affect the perception of interlocutors about their relationship. Therefore, we define a social relationship function $SR$: $Relationship \times context \rightarrow \Im $, that tells which feature say in term of social move. The context represents all the previous knowledge of the speaker. We focus on the relation of dominance in this paper. Thus $Relationship = Dom$ where  $Dom = \{+, -, =\}$ is a three values function. For example, two colleagues have a conversation, colleague \emph{A} speaks \textit{loudly with insurance}, while colleague \emph{B} shows \textit{hesitation} in his talking. Thus, based on the features used in their linguistic style, we can conclude that the colleague \emph{A}  dominates  the colleague \emph{B} (i.e $Dom_{A,B} = +$ and $Dom_{B,A} = -$)
 
\subsubsection{Preferences}
\par Now, that  the model of communication is defined, we introduce the notion of negotiation on preferences. First, lets define the domain of preferences. We assume that the agent expresses its preferences on a defined object based on one or multiple criteria.   
 \begin{itemize}
 \item Objects $O$ : Set of all possible objects of negotiation. For example, negotiate to find at which restaurant have dinner. Note that $O$ is a set of instance of the same type (restaurants in our example): $O=\{Ginza, LeDragonD'Or, Venezzia, \ldots\}$
 \item Criteria $C$: set of criteria or features of preferences on objects. For example, we assume that we can choose a restaurant based on one or several of the following criteria = \{cuisine, ambiance, quality of food, price, location\}. Each criterion has its domain of values that we note: $\forall c \in C$, $D_{c}$ is its domain. For example $D_{cuisine} = \{chineese, italian\}$.

 \item $\forall o \in O, \forall c \in C$, we define $v(c,o) \in D_{c}$ as the objective value of the criterion $c$ attributed to the object $o$. For example, Ginza is an expensive Japanese restaurant. Thus $v(price, Ginza) = expensive$ and $(cuisine, Ginza) = japanese$. 
 
 \item Lets now define interlocutor's preferences. $\forall agent_{i}$ that has to define its preference for an object, for example a restaurant.
 \begin{itemize}
 \item Preferences on criteria of quality related to the object: $Pref_{i}^C (X,Y) $ is a total ordered set of criteria. For example, $ Pref_{i}^{restaurant} (cuisine,price)$ means that the criteria of cuisine is more important for the $agent_{i}$  than the price to choose a restaurant. (To discuss: preferences are a total / partial ordered ?)
 \item Once the criteria is defined, the $agent_{i}$ defines his preferences on the domain of this criteria. Thus, $\forall v_{1} , v_{2} \in D_{C}$, the agent has a  partially ordered preference on these values noted $Pref_{i}^C (v_{1}, v_{2})$  that can be represented as $v_{1}>_{C} v_{2}$ . For example, $agent_{i}:  Pref_{i}^{cuisine} (Japanese , Chinese)$ , means that  $agent_{i}$ prefers the Japanese cuisine over the Chinese. $v_{1} $ and $ v_{2}$ can take other values as presented : 
 \subitem $Pref_{i}^C (v_{1}, *)$ means that $agent_{i}$ prefers the most $v_{1}$. 
 \subitem $Pref_{i}^C (*,v_{2})$ means that $agent_{i}$ doesn't like  $v_{2}$. 
 \subitem $Pref_{i}^C (*,*)$ means that $agent_{i}$ has no preference on $C$. 
 \item The last step consists in defining the agent preferences on the object "restaurant". Based on what we defined above, we conclude that defining a preference on an object is a multi criteria decision \cite{figueira2005multiple}. We denote a function of decision  $Dec$ such that $\forall o_{1}, o_{2} \in O x O, Dec$ define an order of preference on these objects where  $\{o_{1}\prec o_{2}, o_{1} \succ o_{2}, o_{1} \approx o_{2}\}$.
 \end{itemize} 
 \end{itemize}nadi
 
 In the end, the agents try to negociate a choice about an object. The final decision is to select an object (\emph{e.g.} let's go to Ginza), but during the negociation, agents can also propose values for criteria (\emph{e.g.} let's go to a Japanese restaurant). To represent these elements of decision, we will use the following notation:
 \begin{itemize}
   \item $Dec(o)$ represents the fact that the final decision is to choose object $o$ (eg: the Ginza restaurant)
   \item $Dec(c,v)$ represents the fact that the final decision must choose an object that has value $v$ for criteria $c$ (eg: a silent restaurant)
 \end{itemize}

\subsubsection{Belief base and intentions}
In this section we present the agent belief on his preferences. We situate our definition in the context of social conversation between two people. Suppose $i,j \in \{Interolocutors\}$.
\par Following the BDI \cite{rao1991modeling}, we present the following definitions:
\begin{itemize}
	\item  $ B_{i} \varphi$ the fact that $agent_{i}$  believes that a proposition $\varphi$ is true. For example, $Agent_j$ believes that $Agent_{i}$ likes Chinese cuisine is represented $ B_{j} Pref_{i}^{cuisine}(Chinese)$.
	\item  $U_{i} \varphi = \neg B_{i} \varphi \land \neg B_{i} \neg \varphi$, means that the $agent_{i}$ has no belief on $\varphi$.  For example, the fact that $agent_{j}$ ignores what type of cuisine the $agent_{i}$ prefers is formalized : $U_{j} Pref_{i}^{cuisine}(*,*)$.
	\item $I_{i} \varphi$ means that  $agent_i$ has the intention that $\varphi$ is true.

	In our work, we focus on communication of preferences. Therefore, $\varphi = Pref_i^c(x,y)$. we will be considering formulas of the form: $B_j Pref_i^c(x,y)$ (possibly, $i=j$ if we represent an agent belief about its own preferences, and $i\neq j$ when it represents the beliefs about the interlocutor's preferences).
	
	The dialogue is a negotiation about preferences. Therefore, we do not modify the preferences of the other (to be discussed with Chuck). We only have intentions of the form $I_i B_j Pref_i^c(x,y)$: the agent has the intention to change a belief about a preference, with $i\neq j$, or $I_i B_i Pref_j^c(x,y)$, with $i\neq j$.
	
	In our model, these $I_i B_j \varphi$ or $I_i B_i \varphi$ correspond to communications: the agent $i$ has the intention to communicate a preference ($I_i B_j \varphi$) or to obtain the information about the interlocutor's preference ($I_i B_i \varphi$). 
	
	Thus, we can write that $I_{i} \varphi$ means that  $agent_i$ has the intention to communicate about $\varphi$ (in one way or the other: obtain or transmit a preference).
	
	We define axioms of cooperation that allows an agent to respond to a communication. Thus, $ B_{i} \varphi \land  B_{i} U_{j} \varphi \land  B_{i} I_{j}  B_{j} \varphi \implies I_{i}  B_{j} \varphi  $.
	% déplacer après ?
	
	In our model, actions are not built automatically by a planer: the plan is described in an HTN following the Disco \cite{rich2009building} paradigm. Actions are represented hierarchically where complex actions are decomposed to more simpler ones. The action selection is done reactively, where the next action to be executed is selected based on the user response on the previous action. 
	
	% ajouter transition sur comment le plannificateur va utiliser les K (Bi) qu'on met à jour
	
\end{itemize}

% ici axiomes:
% - axiome de coopération
% - axiome de propositions/décision
% $B_i I_j Dec(x) et _cette décision est compatible avec mes prefs_ => I_i Dec(x)
% ou alors à quel moment je rajoute un I_i Dec dans ma base pour faire un propose ?

\subsubsection{Utterances semantic}
Agents communicates using utterances that encapsulate the message. After each communicated utterance, agents will update their beliefs about the preferences of the other agent. Therefore an utterance is communicated to a need to update a belief. In the following, we suppose that $agent_{i}$ is the speaker and $agent_{j}$ is the hearer. As messages are actions, they are defined with precondition and effects on the belief. The preconditions are all optional, because the message selection depends first on the agent strategy of conversation. However, defining preconditions allow us to do inferences in order to know the reasons that make the agent choose this action. For example, if the agent changes the subject of discussion and talks about Chinese food, then we can conclude that the agent is dominant enough to lead the dialogue and change the subject of discussion. In addition, the effects are symmetric, we only represent the  agent's belief about its preferences and user preferences. We cannot represent the user belief, we can only represent the agent perception of the user belief. For example, we situate our perception form the agent point of view. Suppose that the agent states that he likes Chinese food.  We can imagine that the reasons (precondition) that lead him  to state its preferences was that the agent believed that the user didn't know the agent preference and the agent also had the intention to inform the user about its preferences. The effect of the statement is that now the agent believes that the user knows that he likes chinese food. 

In the following, we will be presenting  the utterances of dialogue, and we present the effect of this utterences on the agent belief in the case where the agent is either the hearer (\textit{i.e} Agent = $agent_i$) or  the listener(\textit{i.e} Agent = $agent_j$)

%Par exemple, pour le statePref, on peut considérer 2 situations:
%- i=humain, j=agent: si l'humain me dit qu'il aime le chinois, je peux 1) déduire que, probablement, il croyait que je ne le savais pas, 2) il avait l'intention que je le sache (obtenu à partir des préconditions) et 3) qu'il croit que maintenant je le sais et surtout, que moi, maintenant, je le sais: je l'ajoute dans ma base.
%- i=agent, j=humain: si je dis à l'humain que j'aime le chinois, c'est parce que je pensais qu'il ne le savait pas et j'avais envie qu'il le sache. Je ne peux rien dire sur ses croyances mais maintenant, je crois qu'il le sait: j'ajoute cette croyance dans ma base

Keep in mind that:
\begin{itemize}
	\item We cannot change the values of Pref in the dialogue (no action can have any effect on the preferences of the interlocutor)
	\item The effects of the sender of the message are always of the form $B_i Effects(j)$, but in some situation this does not bring any useful knowledge for the reactive planer.
\end{itemize}

 \begin{itemize}
 \item State.Preference(\textit{$P_{1}, P_{2}$}) : I prefer $P_{1}$ over $P_{2}$.
 \subitem Preconditions(i):  $ B_{i} U_{j} Pref_{i}(P_{1}, P_{2}), I_{i} B_{j} Pref_{i}(P_{1}, P_{2})$
 \subitem Effects(j): $ B_{j} Pref_{i}(P_{1}, P_{2})$
 \subitem Effects(i): $ B_i Effect(j)$ (not really useful for the agent to know that the user knows its preferences ?)
 \\ We define two variant valuations on stating preferences as follows: 
 \subitem State.Preference(\textit{$P_{i}, *$}): I prefer the most $P_{i}$.
 \subitem State.Preference(\textit{$*, P_{i}$}): I don't like /hate $P_{i}$.
\subitem Example: State.Preference(\textit{$Pref_{i}^{cuisine} (Japanese , Chinese)$}) : I prefer japanese cuisine over chinese.
 \item Ask.Preference(\textit{$P_{1}, P_{2}$}) : Do you prefer $P_{1}$ to $P_{2}$ ?. 
  \subitem Preconditions:  $ U_{i} Pref_{j}(P_{1}, P_{2})$ ,  $ I_{i} B_{i} Pref_{j}(P_{1}, P_{2})$
  \subitem Effects (j):  $B_{j} U_{i} Pref_{j}(P_{1}, P_{2})$ ,  $ B_{j} I_{i} B_{i}Pref_{j}(P_{1}, P_{2})$
   \subitem Effects(i): $ B_i Effect(j)$ (not really useful for the agent to know that the user knows that the agent wants to know, imho)
 \\We define two variant valuations as follows: 
 \subitem Ask.Preference(\textit{$Pref_{j}(P_{1}, *)$}): Do you like $P_{1}$?
 \subitem Ask.Preference(\textit{$*$}): What do you like ?. This case appear when the speaker has no belief on the hear preferences. 
 \subitem Example: Ask.Preference(\textit{$Pref_{i}^{cuisine} (Japanese , Chinese)$}) : Do you prefer japanese cuisine or chinese?

 \item Ask.Object(): Which "Object" do you want to choose ? For example we consider Object = Restaurant. Note that Ask.Object has no content. Since we consider a single-object negotiation, the participants have to chose one single element in $O$. The semantic of the utterance Ask.Object means that the sender asks the hearer to propose an instance $o\in O$.
	\subitem Preconditions:  $ U_{i} Pref_{j}(P_{1}, P_{2})$ ,  $ I_{i} B_{i} Pref_{j}(P_{1}, P_{2})$
  	\subitem Effects (j):  $B_{j} U_{i} Pref_{j}(P_{1}, P_{2})$ ,  $ B_{j} I_{i} B_{i}Pref_{j}(P_{1}, P_{2})$
 
 \item Propose.Criteria(\textit{V(criteria, value)}): I think that \textit{value}  would be great. 
  \subitem Preconditions:  $ I_{i} Dec(criteria, value) $
  \subitem Effects:  $B_{j} I_{i} Dec(criteria, value)$
   \subitem Example: Propose.Preference(\textit{$V(cuisine,Japanese$}) : I want to taste japanese food.
 \item Accept.Criteria(\textit{V(criteria, value)}): Okay, let's choose \textit{value}. After receiving a propose utterance from the $agent_{j}$,  $agent_{i}$ might accept the proposal.
   \subitem Effects:  $B_{i,j} Pref_{i,j}(V(criteria, value))$
   
 \item Reject.Criteria(\textit{V(criteria, value)}): Sorry, I would choice something else.
    \subitem Effects:  $B_{i} \neg  Pref_{j}(V(criteria, value))$
 
  \item Propose.Object(\textit{object}): I think that \textit{object} would be great.
  \subitem Preconditions:  $ I_{i} Pref_{j}(object)$
  
  \subitem Effects:  $B_{j} I_{i} Pref_{j}(object)$ ,  $ B_{j} Pref_{i}(object)$  
  \item Accept.Object(\textit{object}): Okay, let's choose \textit{value}.
     \subitem Effects:  $B_{i,j} Pref_{i,j}(object)$ 
  
  \item Reject.Object(\textit{object}): Sorry, I would choice something else.
      \subitem Effects:  $B_{i} \neg  Pref_{j}(object)$
 \end{itemize} 
 \subsection{Find utterances in dialogs}	
 
 In the following I represented the utterances in the hand made dialogues. When analyzing the recorded dialogues, the utterances appears in a more implicit manner. For example, when Lauriane says: " Sinon j'aime bien japonais". here its a State.preference(Lauriane, leonor,japonais).Loenor perceives it as a propose and make a reject by saying : "Je n'aime pas du tout le japonais."
 Dialogue	Utterance

 \subsection{Synthetic dialogue with utterances}
 In this section, I present a synthetic dialogue to illustrate the language definition.Yhe goal of the agent is to invite the user to a restaurant. The Agent has a predefined list of preferences of types of food (AgentPreferences = \{ +Indian, +Italian, -Japanese\}) and the agent has no information on user preferences (UserPreferences = \{\}). In this example the Agent is peer with the user. 


\begin{minipage}{0.45\textwidth}
 
\end{minipage}%
\hfill
\begin{minipage}{0.45\textwidth}

\end{minipage}%


\noindent 
\vskip 4pt
\bibliographystyle{plain}
\bibliography{abbrevs,Library}
\end{document}
